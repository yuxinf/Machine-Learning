{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chevalier\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "data = scipy.io.loadmat('MSdata.mat')\n",
    "import random\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[\"trainx\"],data[\"trainy\"], test_size =0.2, random_state = 30 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chevalier\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "#from sklearn.svm import SVR\n",
    "estimator = LinearRegression()\n",
    "selector = RFE(estimator, 10, step=8)\n",
    "selector = selector.fit(X_train, y_train)\n",
    "\n",
    "X_train = selector.transform(X_train)\n",
    "X_test = selector.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chevalier\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype uint16 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range=(0,1))\n",
    "X_train_s = sc.fit_transform(X_train) \n",
    "X_test_s = sc.fit_transform(X_test)\n",
    "y_train_s = sc.fit_transform(y_train)\n",
    "y_test_s = sc.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_s = X_train_s.reshape((X_train_s.shape[0], 1, X_train_s.shape[1]))\n",
    "\n",
    "#X_train_s = numpy.reshape(X_train_s, (X_train_s.shape[0], X_train_s.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(370972, 1, 10) (370972, 1) (92743, 1, 10) (92743, 1)\n"
     ]
    }
   ],
   "source": [
    "X_test_s = X_test_s.reshape((X_test_s.shape[0], 1, X_test_s.shape[1]))\n",
    "\n",
    "print(X_train_s.shape, y_train_s.shape, X_test_s.shape, y_test_s.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 370972 samples, validate on 92743 samples\n",
      "Epoch 1/80\n",
      " - 29s - loss: 0.0266 - val_loss: 0.0134\n",
      "Epoch 2/80\n",
      " - 25s - loss: 0.0128 - val_loss: 0.0150\n",
      "Epoch 3/80\n",
      " - 25s - loss: 0.0124 - val_loss: 0.0155\n",
      "Epoch 4/80\n",
      " - 25s - loss: 0.0123 - val_loss: 0.0154\n",
      "Epoch 5/80\n",
      " - 25s - loss: 0.0123 - val_loss: 0.0152\n",
      "Epoch 6/80\n",
      " - 25s - loss: 0.0122 - val_loss: 0.0158\n",
      "Epoch 7/80\n",
      " - 25s - loss: 0.0122 - val_loss: 0.0155\n",
      "Epoch 8/80\n",
      " - 25s - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 9/80\n",
      " - 25s - loss: 0.0121 - val_loss: 0.0153\n",
      "Epoch 10/80\n",
      " - 25s - loss: 0.0121 - val_loss: 0.0154\n",
      "Epoch 11/80\n",
      " - 25s - loss: 0.0120 - val_loss: 0.0154\n",
      "Epoch 12/80\n",
      " - 25s - loss: 0.0120 - val_loss: 0.0158\n",
      "Epoch 13/80\n",
      " - 25s - loss: 0.0120 - val_loss: 0.0160\n",
      "Epoch 14/80\n",
      " - 25s - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 15/80\n",
      " - 25s - loss: 0.0120 - val_loss: 0.0154\n",
      "Epoch 16/80\n",
      " - 25s - loss: 0.0120 - val_loss: 0.0161\n",
      "Epoch 17/80\n",
      " - 25s - loss: 0.0120 - val_loss: 0.0153\n",
      "Epoch 18/80\n",
      " - 25s - loss: 0.0120 - val_loss: 0.0153\n",
      "Epoch 19/80\n",
      " - 25s - loss: 0.0120 - val_loss: 0.0158\n",
      "Epoch 20/80\n",
      " - 25s - loss: 0.0120 - val_loss: 0.0158\n",
      "Epoch 21/80\n",
      " - 25s - loss: 0.0120 - val_loss: 0.0163\n",
      "Epoch 22/80\n",
      " - 25s - loss: 0.0120 - val_loss: 0.0161\n",
      "Epoch 23/80\n",
      " - 25s - loss: 0.0119 - val_loss: 0.0159\n",
      "Epoch 24/80\n",
      " - 25s - loss: 0.0119 - val_loss: 0.0164\n",
      "Epoch 25/80\n",
      " - 25s - loss: 0.0119 - val_loss: 0.0161\n",
      "Epoch 26/80\n",
      " - 25s - loss: 0.0119 - val_loss: 0.0163\n",
      "Epoch 27/80\n",
      " - 25s - loss: 0.0119 - val_loss: 0.0159\n",
      "Epoch 28/80\n",
      " - 25s - loss: 0.0119 - val_loss: 0.0168\n",
      "Epoch 29/80\n",
      " - 25s - loss: 0.0119 - val_loss: 0.0167\n",
      "Epoch 30/80\n",
      " - 25s - loss: 0.0119 - val_loss: 0.0158\n",
      "Epoch 31/80\n",
      " - 25s - loss: 0.0119 - val_loss: 0.0158\n",
      "Epoch 32/80\n",
      " - 25s - loss: 0.0119 - val_loss: 0.0157\n",
      "Epoch 33/80\n",
      " - 25s - loss: 0.0119 - val_loss: 0.0160\n",
      "Epoch 34/80\n",
      " - 25s - loss: 0.0119 - val_loss: 0.0156\n",
      "Epoch 35/80\n",
      " - 25s - loss: 0.0119 - val_loss: 0.0158\n",
      "Epoch 36/80\n",
      " - 25s - loss: 0.0119 - val_loss: 0.0154\n",
      "Epoch 37/80\n",
      " - 25s - loss: 0.0119 - val_loss: 0.0148\n",
      "Epoch 38/80\n",
      " - 25s - loss: 0.0119 - val_loss: 0.0156\n",
      "Epoch 39/80\n",
      " - 25s - loss: 0.0119 - val_loss: 0.0152\n",
      "Epoch 40/80\n",
      " - 25s - loss: 0.0119 - val_loss: 0.0153\n",
      "Epoch 41/80\n",
      " - 25s - loss: 0.0119 - val_loss: 0.0152\n",
      "Epoch 42/80\n",
      " - 25s - loss: 0.0119 - val_loss: 0.0156\n",
      "Epoch 43/80\n",
      " - 25s - loss: 0.0119 - val_loss: 0.0146\n",
      "Epoch 44/80\n",
      " - 25s - loss: 0.0119 - val_loss: 0.0148\n",
      "Epoch 45/80\n",
      " - 25s - loss: 0.0119 - val_loss: 0.0149\n",
      "Epoch 46/80\n",
      " - 25s - loss: 0.0119 - val_loss: 0.0151\n",
      "Epoch 47/80\n",
      " - 25s - loss: 0.0119 - val_loss: 0.0151\n",
      "Epoch 48/80\n",
      " - 25s - loss: 0.0119 - val_loss: 0.0147\n",
      "Epoch 49/80\n",
      " - 25s - loss: 0.0119 - val_loss: 0.0147\n",
      "Epoch 50/80\n",
      " - 25s - loss: 0.0118 - val_loss: 0.0146\n",
      "Epoch 51/80\n",
      " - 25s - loss: 0.0118 - val_loss: 0.0149\n",
      "Epoch 52/80\n",
      " - 25s - loss: 0.0118 - val_loss: 0.0145\n",
      "Epoch 53/80\n",
      " - 25s - loss: 0.0118 - val_loss: 0.0145\n",
      "Epoch 54/80\n",
      " - 25s - loss: 0.0118 - val_loss: 0.0144\n",
      "Epoch 55/80\n",
      " - 25s - loss: 0.0118 - val_loss: 0.0143\n",
      "Epoch 56/80\n",
      " - 25s - loss: 0.0118 - val_loss: 0.0144\n",
      "Epoch 57/80\n",
      " - 25s - loss: 0.0118 - val_loss: 0.0142\n",
      "Epoch 58/80\n",
      " - 25s - loss: 0.0118 - val_loss: 0.0141\n",
      "Epoch 59/80\n",
      " - 25s - loss: 0.0118 - val_loss: 0.0140\n",
      "Epoch 60/80\n",
      " - 25s - loss: 0.0118 - val_loss: 0.0143\n",
      "Epoch 61/80\n",
      " - 25s - loss: 0.0118 - val_loss: 0.0140\n",
      "Epoch 62/80\n",
      " - 25s - loss: 0.0118 - val_loss: 0.0140\n",
      "Epoch 63/80\n",
      " - 25s - loss: 0.0118 - val_loss: 0.0142\n",
      "Epoch 64/80\n",
      " - 25s - loss: 0.0118 - val_loss: 0.0139\n",
      "Epoch 65/80\n",
      " - 25s - loss: 0.0118 - val_loss: 0.0139\n",
      "Epoch 66/80\n",
      " - 25s - loss: 0.0118 - val_loss: 0.0140\n",
      "Epoch 67/80\n",
      " - 25s - loss: 0.0118 - val_loss: 0.0140\n",
      "Epoch 68/80\n",
      " - 25s - loss: 0.0118 - val_loss: 0.0142\n",
      "Epoch 69/80\n",
      " - 25s - loss: 0.0118 - val_loss: 0.0140\n",
      "Epoch 70/80\n",
      " - 25s - loss: 0.0118 - val_loss: 0.0139\n",
      "Epoch 71/80\n",
      " - 25s - loss: 0.0118 - val_loss: 0.0139\n",
      "Epoch 72/80\n",
      " - 25s - loss: 0.0118 - val_loss: 0.0140\n",
      "Epoch 73/80\n",
      " - 27s - loss: 0.0118 - val_loss: 0.0139\n",
      "Epoch 74/80\n",
      " - 30s - loss: 0.0118 - val_loss: 0.0139\n",
      "Epoch 75/80\n",
      " - 28s - loss: 0.0118 - val_loss: 0.0139\n",
      "Epoch 76/80\n",
      " - 29s - loss: 0.0118 - val_loss: 0.0140\n",
      "Epoch 77/80\n",
      " - 28s - loss: 0.0118 - val_loss: 0.0139\n",
      "Epoch 78/80\n",
      " - 27s - loss: 0.0118 - val_loss: 0.0139\n",
      "Epoch 79/80\n",
      " - 28s - loss: 0.0118 - val_loss: 0.0140\n",
      "Epoch 80/80\n",
      " - 28s - loss: 0.0118 - val_loss: 0.0138\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12e84eaa668>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor = Sequential()\n",
    "\n",
    "regressor.add(LSTM(units = 20, return_sequences = True, input_shape=(X_train_s.shape[1], X_train_s.shape[2])))\n",
    "regressor.add(Dropout(0.2))\n",
    "#regressor.add(LSTM(50, input_shape=(X_train_s.shape[1], X_train_s.shape[2])))\n",
    "regressor.add(LSTM(units = 20, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "regressor.add(LSTM(units = 20, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "regressor.add(LSTM(units = 20, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "regressor.add(LSTM(units = 20))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "regressor.add(Dense(1))\n",
    "#regressor.compile(loss='mae', optimizer='adam')\n",
    "regressor.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "regressor.fit(X_train_s, y_train_s, epochs = 80, batch_size = 72, validation_data=(X_test_s, y_test_s), verbose=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1997.8086],\n",
       "       [1998.1937],\n",
       "       [1996.303 ],\n",
       "       ...,\n",
       "       [1999.5562],\n",
       "       [1997.3315],\n",
       "       [1994.0178]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = regressor.predict(X_test_s)\n",
    "y_pred = sc.inverse_transform(y_pred)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2010],\n",
       "       [1982],\n",
       "       [1967],\n",
       "       ...,\n",
       "       [2003],\n",
       "       [1970],\n",
       "       [2005]], dtype=uint16)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.96209148]\n"
     ]
    }
   ],
   "source": [
    "def test_linear(y_pred, y_test):\n",
    "    n = len(y_pred)\n",
    "    total = 0\n",
    "    for i in range(n):\n",
    "        total += abs(y_pred[i]-y_test[i][0])\n",
    "    mae = total/n\n",
    "    return mae    \n",
    "\n",
    "well = test_linear(y_pred, y_test)\n",
    "print(well)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
